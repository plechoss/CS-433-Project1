{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from global_variables import *\n",
    "from data_preparation import * \n",
    "from cost import * \n",
    "from cross_validation import *\n",
    "from performances import * \n",
    "from proj1_helpers import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing performances for least-squares, Ridge-regression and logistic-regression Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 # ten fold CV\n",
    "k_fold = k \n",
    "y = Y \n",
    "x = X\n",
    "seed = 20\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "clean_method = 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10578006553351726 1.4943921777054187e-05\n"
     ]
    }
   ],
   "source": [
    "method = 'least-squares'\n",
    "err_cv_tr_ls, err_cv_te_ls = cross_validation(y, x, k_indices, k, method, None, 1,  1,  0 , 0, clean_method)\n",
    "print(np.mean(err_cv_tr_ls), np.var(err_cv_tr_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-10\n"
     ]
    }
   ],
   "source": [
    "method = 'ridge-regression'\n",
    "lambdas = np.logspace(-10, -8, 30) # Range through \"dichotomous\" search\n",
    "err_lambda = np.empty(len(lambdas))\n",
    "for index_lambda, lambda_ in enumerate(lambdas):\n",
    "    _, err_cv_val = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "    err_lambda[index_lambda] = np.mean(err_cv_val) \n",
    "# best_lambda chosen to minimize the mean generalization error\n",
    "best_lambda = lambdas[np.argmin(err_lambda)]\n",
    "# The code should also provide the corresponding error values \n",
    "print(best_lambda)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1057800691212261 1.4943838914801378e-05\n"
     ]
    }
   ],
   "source": [
    "# Probably would be smarter to get the errors directly above ...\n",
    "method = 'ridge-regression'\n",
    "lambda_ = best_lambda\n",
    "err_cv_tr_ridge, err_cv_te_ridge = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr_ridge), np.var(err_cv_tr_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-725a9efa2458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0merr_gamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgammas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgammas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_cv_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0merr_gamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_gamma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_cv_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# best_gamma chosen to minimize the mean generalization error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\ML_P1\\CS-433-Project1\\scripts\\cross_validation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m# Test ML algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mw_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mML_methods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_tr_sel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mloss_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val_sel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\ML_P1\\CS-433-Project1\\scripts\\cost.py\u001b[0m in \u001b[0;36mML_methods\u001b[1;34m(y, tx, method, initial_w, batch_size, max_iters, gamma, lambda_)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32melif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'log-newton'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_regression_Newton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\ML_P1\\CS-433-Project1\\scripts\\cost.py\u001b[0m in \u001b[0;36mlogistic_regression_Newton\u001b[1;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;34m\" Logistic regression using Newton's method \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"log-newton\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\ML_P1\\CS-433-Project1\\scripts\\cost.py\u001b[0m in \u001b[0;36mgradient_descent\u001b[1;34m(y, tx, initial_w, max_iters, gamma, method, lambda_)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m# perform 1 iteration of gradient descent with the chosen method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'log-newton'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\ML_P1\\CS-433-Project1\\scripts\\cost.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(y, tx, w, method, lambda_)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32melif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'log'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'regularized-log'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'log-newton'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-5\u001b[0m   \u001b[1;31m# parameter to ensure a real value is returned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_iters= 500\n",
    "method = 'log-newton'\n",
    "gammas = np.logspace(-10, 0, 30)\n",
    "err_gamma = np.empty(len(gammas))\n",
    "for index_gamma, gamma in enumerate(gammas):\n",
    "    _, err_cv_val = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "    err_gamma[index_gamma] = np.mean(err_cv_val) \n",
    "# best_gamma chosen to minimize the mean generalization error\n",
    "best_gamma = gammas[np.argmin(err_gamma)]\n",
    "# The code should also provide the corresponding error values \n",
    "print(best_gamma)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably would be smarter to get the errors directly above ...\n",
    "gamma = best_gamma\n",
    "err_cv_tr_newton, err_cv_te = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr_newton), np.var(err_cv_tr_newton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO : \n",
    "# Do it for clean_method in ['raw', '', '0', 'mean', 'media']\n",
    "# for all 3 methods ('least-squares', 'ridge-regression', 'log-newton')\n",
    "# Add the accuracy\n",
    "# Write a script working for all hyper-parameters (gamma for newton et lambda for ridge) ?! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if all functions work well but not to be included "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 # ten fold CV\n",
    "k_fold = k \n",
    "y = Y \n",
    "x = X\n",
    "seed = 20\n",
    "k_indices = build_k_indices(y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable to decide on cleaning method ( see function clean_features)\n",
    "clean_method = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares normal eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10628603762801525 5.516271597259191e-06\n"
     ]
    }
   ],
   "source": [
    "method = 'least-squares'\n",
    "err_cv_tr, err_cv_te = cross_validation(y, x, k_indices, k, method, None, 1,  1,  0 , 0, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares GD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9897983158778125 0.01956881224911784\n"
     ]
    }
   ],
   "source": [
    "method = 'least-squares-GD'\n",
    "max_iters = 50\n",
    "gamma = 0.01\n",
    "batch_size = 1\n",
    "initial_w = None\n",
    "lambda_ = 0\n",
    "err_cv_tr, err_cv_te = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least-squares SGD  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1656511456357348 0.5725855745062298\n"
     ]
    }
   ],
   "source": [
    "method = 'least-squares-SGD' \n",
    "err_cv_tr, err_cv_te = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1500700532153169 3.042030522074035e-08\n"
     ]
    }
   ],
   "source": [
    "method = 'ridge-regression'\n",
    "lambda_ = 1\n",
    "err_cv_tr, err_cv_te = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9842606890968806 0.00592770602653977\n"
     ]
    }
   ],
   "source": [
    "method = 'log'\n",
    "initial_w = np.zeros(x.shape[1])\n",
    "err_cv_tr, err_cv_te = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4687536518687443 0.10673300434066402\n"
     ]
    }
   ],
   "source": [
    "method = 'regularized-log'\n",
    "initial_w = np.zeros(x.shape[1])\n",
    "err_cv_tr, err_cv_te = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing models with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "method = 'ridge-regression'\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "err_lambda = np.empty(len(lambdas))\n",
    "for index_lambda, lambda_ in enumerate(lambdas):\n",
    "    err_cv_tr, err_cv_val = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "    err_lambda[index_lambda] = np.mean(err_cv_val) \n",
    "best_lambda = lambdas[np.argmin(err_lambda)]\n",
    "# The code should also provide the corresponding error values \n",
    "print(best_lambda)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10631253516169892 5.341317015924967e-06\n"
     ]
    }
   ],
   "source": [
    "method = 'ridge-regression'\n",
    "lambda_ = best_lambda\n",
    "err_cv_tr, err_cv_te = cross_validation(y, x, k_indices, k, method, initial_w, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
