{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from global_variables import *\n",
    "from data_preparation import * \n",
    "from cost import * \n",
    "from cross_validation import *\n",
    "from performances import * \n",
    "from proj1_helpers import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing performances for least-squares, Ridge-regression and logistic-regression Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 # ten fold CV\n",
    "k_fold = k \n",
    "y = Y \n",
    "x = X\n",
    "seed = 20\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  7  8  9 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29]\n",
      "[ 2  7  8 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29]\n",
      "[ 2  7  8 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29]\n",
      "[ 2  7  8 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29]\n",
      "[ 2  7  8 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29]\n",
      "[ 2  7  8 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29]\n",
      "[ 2  7  8 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29]\n",
      "[ 2  7  8 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29]\n",
      "[ 2  7  8 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29]\n",
      "[ 2  7  8 14 15 16 17 18 19 20 21 22 24 25 26 27 28 29]\n",
      "0.08945985342093368 0.00017670354630962715 0.73084\n"
     ]
    }
   ],
   "source": [
    "clean_method = '0'\n",
    "method = 'least-squares'\n",
    "err_cv_tr_ls, err_cv_te_ls, accuracy = cross_validation(y, x, k_indices, k, method, 1,  1,  0 , 0, clean_method)\n",
    "print(np.mean(err_cv_tr_ls), np.std(err_cv_tr_ls), np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_method = 'mean'\n",
    "method = 'ridge-regression'\n",
    "lambdas = np.logspace(-10, -2, 10) # Range through \"dichotomous\" search\n",
    "err_lambda = np.empty(len(lambdas))\n",
    "for index_lambda, lambda_ in enumerate(lambdas):\n",
    "    _, err_cv_val, accuracy = cross_validation(y, x, k_indices, k, method, 1, 1, 0, lambda_, clean_method)\n",
    "    err_lambda[index_lambda] = np.mean(err_cv_val) \n",
    "# best_lambda chosen to minimize the mean generalization error\n",
    "best_lambda = lambdas[np.argmin(err_lambda)]\n",
    "# The code should also provide the corresponding error values \n",
    "print(best_lambda)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably would be smarter to get the errors directly above ...\n",
    "method = 'ridge-regression'\n",
    "lambda_ = best_lambda\n",
    "err_cv_tr_ridge, err_cv_te_ridge, accuracy = cross_validation(y, x, k_indices, k, method, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr_ridge), np.var(err_cv_tr_ridge), accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters= 10\n",
    "method = 'log-newton'\n",
    "gammas = np.logspace(-10, 0, 30)\n",
    "err_gamma = np.empty(len(gammas))\n",
    "for index_gamma, gamma in enumerate(gammas):\n",
    "    _, err_cv_val, accuracy = cross_validation(y, x, k_indices, k, method, 1, max_iters, gamma, lambda_, clean_method)\n",
    "    err_gamma[index_gamma] = np.mean(err_cv_val) \n",
    "# best_gamma chosen to minimize the mean generalization error\n",
    "best_gamma = gammas[np.argmin(err_gamma)]\n",
    "# The code should also provide the corresponding error values \n",
    "print(best_gamma)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably would be smarter to get the errors directly above ...\n",
    "gamma = best_gamma\n",
    "err_cv_tr_newton, err_cv_te, accuracy = cross_validation(y, x, k_indices, k, method, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr_newton), np.var(err_cv_tr_newton), accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO : \n",
    "# Do it for clean_method in ['raw', '', '0', 'mean', 'media']\n",
    "# for all 3 methods ('least-squares', 'ridge-regression', 'log-newton')\n",
    "# Add the accuracy\n",
    "# Write a script working for all hyper-parameters (gamma for newton et lambda for ridge) ?! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if all functions work well but not to be included "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 # ten fold CV\n",
    "k_fold = k \n",
    "y = Y \n",
    "x = X\n",
    "seed = 20\n",
    "k_indices = build_k_indices(y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable to decide on cleaning method ( see function clean_features)\n",
    "clean_method = 'median'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares normal eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'least-squares'\n",
    "err_cv_tr, err_cv_te, accuracy = cross_validation(y, x, k_indices, k, method, 1,  1,  0 , 0, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr), accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares GD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'least-squares-GD'\n",
    "max_iters = 50\n",
    "gamma = 0.01\n",
    "batch_size = 1\n",
    "lambda_ = 0\n",
    "err_cv_tr, err_cv_te, accuracy = cross_validation(y, x, k_indices, k, method, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr), accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least-squares SGD  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "method = 'least-squares-SGD' \n",
    "err_cv_tr, err_cv_te, accuracy = cross_validation(y, x, k_indices, k, method, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr), accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'ridge-regression'\n",
    "lambda_ = 1\n",
    "err_cv_tr, err_cv_te, accuracy = cross_validation(y, x, k_indices, k, method, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr), accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "method = 'log'\n",
    "err_cv_tr, err_cv_te, accuracy = cross_validation(y, x, k_indices, k, method, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr), accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'regularized-log'\n",
    "err_cv_tr, err_cv_te, accuracy = cross_validation(y, x, k_indices, k, method, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr), accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'log-newton'\n",
    "err_cv_tr, err_cv_te, accuracy = cross_validation(y, x, k_indices, k, method, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr), accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing models with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CV testing gamma and lambda inside same loop\n",
    "\n",
    "X, Y = load_data()\n",
    "k = 10 # ten fold CV\n",
    "k_fold = k \n",
    "y = Y \n",
    "x = X\n",
    "seed = 20\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "clean_method = '0'\n",
    "batch_size = 1\n",
    "max_iters = 100\n",
    "\n",
    "method = 'regularized-log'\n",
    "lambdas = np.logspace(-5, 3, 8)\n",
    "#lambdas = [0]\n",
    "gammas = np.logspace(-20, 2, 13)\n",
    "err = np.empty([len(lambdas), len(gammas)])\n",
    "acc = np.empty([len(lambdas), len(gammas)])\n",
    "for index_lambda, lambda_ in enumerate(lambdas):\n",
    "    print(\"L: \" + str(index_lambda) + \"  \"+str(lambda_))\n",
    "    for index_gamma, gamma in enumerate(gammas):\n",
    "        print(\"G: \" + str(index_gamma) + \"  \"+ str(gamma))\n",
    "        err_cv_tr, err_cv_val, accuracy = cross_validation(y, x, k_indices, k, method, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "        err[index_lambda, index_gamma] = np.mean(err_cv_val)\n",
    "        print(np.mean(err_cv_val))\n",
    "        acc[index_lambda, index_gamma] = accuracy\n",
    "        print(accuracy)\n",
    "print(err)\n",
    "print(acc)\n",
    "best_combination = np.argwhere(err == np.min(err))\n",
    "print(\"least error where :\" + str(best_combination))\n",
    "best_acc = np.argwhere(acc == np.max(acc))\n",
    "print(\"highest accuracy where :\" + str(best_acc))\n",
    "best_lambda = lambdas[best_combination[0][0]]\n",
    "best_gamma = gammas[best_combination[0][1]]\n",
    "# The code should also provide the corresponding error values \n",
    "print(\"Best lambda: \" + str(best_lambda))\n",
    "print(\"Best gamma: \" + str(best_gamma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'ridge-regression'\n",
    "lambda_ = best_lambda\n",
    "err_cv_tr, err_cv_te, accuracy = cross_validation(y, x, k_indices, k, method, batch_size, max_iters, gamma, lambda_, clean_method)\n",
    "print(np.mean(err_cv_tr), np.var(err_cv_tr), accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
